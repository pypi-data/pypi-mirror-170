{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df7c8824",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T15:24:21.287123Z",
     "start_time": "2022-04-14T15:24:21.265791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/home/ubuntu/varios/skforecast\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent))\n",
    "%config Completer.use_jedi = False\n",
    "print(str(Path.cwd().parent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f9a85a",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58184bff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T15:24:23.165175Z",
     "start_time": "2022-04-14T15:24:22.494521Z"
    }
   },
   "outputs": [],
   "source": [
    "# random search forecaster\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from skforecast.model_selection.model_selection import bayesian_search_forecaster\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregCustom import ForecasterAutoregCustom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "360794f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T15:24:25.448031Z",
     "start_time": "2022-04-14T15:24:25.134042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dates      : 1991-07-01 00:00:00 --- 2001-01-01 00:00:00  (n=115)\n",
      "Validation dates : 2001-02-01 00:00:00 --- 2006-01-01 00:00:00  (n=60)\n",
      "Test dates       : 2006-02-01 00:00:00 --- 2008-06-01 00:00:00  (n=29)\n"
     ]
    }
   ],
   "source": [
    "# Download data\n",
    "# ==============================================================================\n",
    "url = ('https://raw.githubusercontent.com/JoaquinAmatRodrigo/skforecast/master/data/h2o.csv')\n",
    "data = pd.read_csv(url, sep=',', header=0, names=['y', 'datetime'])\n",
    "\n",
    "# Data preprocessing\n",
    "# ==============================================================================\n",
    "data['datetime'] = pd.to_datetime(data['datetime'], format='%Y/%m/%d')\n",
    "data = data.set_index('datetime')\n",
    "data = data.asfreq('MS')\n",
    "data = data[['y']]\n",
    "data = data.sort_index()\n",
    "\n",
    "# Train-val-test dates\n",
    "# ==============================================================================\n",
    "end_train = '2001-01-01 23:59:00'\n",
    "end_val = '2006-01-01 23:59:00'\n",
    "\n",
    "print(f\"Train dates      : {data.index.min()} --- {data.loc[:end_train].index.max()}  (n={len(data.loc[:end_train])})\")\n",
    "print(f\"Validation dates : {data.loc[end_train:].index.min()} --- {data.loc[:end_val].index.max()}  (n={len(data.loc[end_train:end_val])})\")\n",
    "print(f\"Test dates       : {data.loc[end_val:].index.min()} --- {data.index.max()}  (n={len(data.loc[end_val:])})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "788937b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Tuple, Optional, Any\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler, RandomSampler\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING) # disable optuna logs\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Categorical, Real, Integer\n",
    "\n",
    "from skforecast.model_selection import backtesting_forecaster\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregCustom import ForecasterAutoregCustom\n",
    "from skforecast.ForecasterAutoregDirect import ForecasterAutoregDirect\n",
    "from skforecast.ForecasterAutoregMultiOutput import ForecasterAutoregMultiOutput\n",
    "from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7d29533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 20,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 2/2 [00:05<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 20,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 2/2 [00:05<00:00,  2.76s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 12, 'min_samples_leaf': 3.642...</td>\n",
       "      <td>0.068957</td>\n",
       "      <td>12</td>\n",
       "      <td>3.642341</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 12, 'min_samples_leaf': 2.481...</td>\n",
       "      <td>0.068957</td>\n",
       "      <td>12</td>\n",
       "      <td>2.481767</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 2.272...</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>14</td>\n",
       "      <td>2.272179</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 2.134...</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>14</td>\n",
       "      <td>2.134928</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 2.355...</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>14</td>\n",
       "      <td>2.355124</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.750...</td>\n",
       "      <td>0.069218</td>\n",
       "      <td>17</td>\n",
       "      <td>1.750301</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.901...</td>\n",
       "      <td>0.069218</td>\n",
       "      <td>17</td>\n",
       "      <td>1.901317</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.751...</td>\n",
       "      <td>0.069218</td>\n",
       "      <td>17</td>\n",
       "      <td>1.751693</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 15, 'min_samples_leaf': 2.634...</td>\n",
       "      <td>0.069430</td>\n",
       "      <td>15</td>\n",
       "      <td>2.634133</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 16, 'min_samples_leaf': 1.778...</td>\n",
       "      <td>0.069501</td>\n",
       "      <td>16</td>\n",
       "      <td>1.778914</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.751...</td>\n",
       "      <td>0.070486</td>\n",
       "      <td>17</td>\n",
       "      <td>1.751693</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.750...</td>\n",
       "      <td>0.070486</td>\n",
       "      <td>17</td>\n",
       "      <td>1.750301</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.901...</td>\n",
       "      <td>0.070486</td>\n",
       "      <td>17</td>\n",
       "      <td>1.901317</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 16, 'min_samples_leaf': 1.778...</td>\n",
       "      <td>0.070671</td>\n",
       "      <td>16</td>\n",
       "      <td>1.778914</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 15, 'min_samples_leaf': 2.634...</td>\n",
       "      <td>0.070912</td>\n",
       "      <td>15</td>\n",
       "      <td>2.634133</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 2.272...</td>\n",
       "      <td>0.071127</td>\n",
       "      <td>14</td>\n",
       "      <td>2.272179</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 2.134...</td>\n",
       "      <td>0.071127</td>\n",
       "      <td>14</td>\n",
       "      <td>2.134928</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 2.355...</td>\n",
       "      <td>0.071127</td>\n",
       "      <td>14</td>\n",
       "      <td>2.355124</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 12, 'min_samples_leaf': 2.481...</td>\n",
       "      <td>0.071194</td>\n",
       "      <td>12</td>\n",
       "      <td>2.481767</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 12, 'min_samples_leaf': 3.642...</td>\n",
       "      <td>0.071194</td>\n",
       "      <td>12</td>\n",
       "      <td>3.642341</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               lags                                             params  \\\n",
       "19        [1, 2, 3]  {'n_estimators': 12, 'min_samples_leaf': 3.642...   \n",
       "14        [1, 2, 3]  {'n_estimators': 12, 'min_samples_leaf': 2.481...   \n",
       "13        [1, 2, 3]  {'n_estimators': 14, 'min_samples_leaf': 2.272...   \n",
       "12        [1, 2, 3]  {'n_estimators': 14, 'min_samples_leaf': 2.134...   \n",
       "18        [1, 2, 3]  {'n_estimators': 14, 'min_samples_leaf': 2.355...   \n",
       "16        [1, 2, 3]  {'n_estimators': 17, 'min_samples_leaf': 1.750...   \n",
       "11        [1, 2, 3]  {'n_estimators': 17, 'min_samples_leaf': 1.901...   \n",
       "10        [1, 2, 3]  {'n_estimators': 17, 'min_samples_leaf': 1.751...   \n",
       "17        [1, 2, 3]  {'n_estimators': 15, 'min_samples_leaf': 2.634...   \n",
       "15        [1, 2, 3]  {'n_estimators': 16, 'min_samples_leaf': 1.778...   \n",
       "0   [1, 2, 3, 4, 5]  {'n_estimators': 17, 'min_samples_leaf': 1.751...   \n",
       "6   [1, 2, 3, 4, 5]  {'n_estimators': 17, 'min_samples_leaf': 1.750...   \n",
       "1   [1, 2, 3, 4, 5]  {'n_estimators': 17, 'min_samples_leaf': 1.901...   \n",
       "5   [1, 2, 3, 4, 5]  {'n_estimators': 16, 'min_samples_leaf': 1.778...   \n",
       "7   [1, 2, 3, 4, 5]  {'n_estimators': 15, 'min_samples_leaf': 2.634...   \n",
       "3   [1, 2, 3, 4, 5]  {'n_estimators': 14, 'min_samples_leaf': 2.272...   \n",
       "2   [1, 2, 3, 4, 5]  {'n_estimators': 14, 'min_samples_leaf': 2.134...   \n",
       "8   [1, 2, 3, 4, 5]  {'n_estimators': 14, 'min_samples_leaf': 2.355...   \n",
       "4   [1, 2, 3, 4, 5]  {'n_estimators': 12, 'min_samples_leaf': 2.481...   \n",
       "9   [1, 2, 3, 4, 5]  {'n_estimators': 12, 'min_samples_leaf': 3.642...   \n",
       "\n",
       "    mean_squared_error  n_estimators  min_samples_leaf max_features  \n",
       "19            0.068957            12          3.642341         sqrt  \n",
       "14            0.068957            12          2.481767         sqrt  \n",
       "13            0.069073            14          2.272179         log2  \n",
       "12            0.069073            14          2.134928         log2  \n",
       "18            0.069073            14          2.355124         log2  \n",
       "16            0.069218            17          1.750301         log2  \n",
       "11            0.069218            17          1.901317         sqrt  \n",
       "10            0.069218            17          1.751693         sqrt  \n",
       "17            0.069430            15          2.634133         log2  \n",
       "15            0.069501            16          1.778914         log2  \n",
       "0             0.070486            17          1.751693         sqrt  \n",
       "6             0.070486            17          1.750301         log2  \n",
       "1             0.070486            17          1.901317         sqrt  \n",
       "5             0.070671            16          1.778914         log2  \n",
       "7             0.070912            15          2.634133         log2  \n",
       "3             0.071127            14          2.272179         log2  \n",
       "2             0.071127            14          2.134928         log2  \n",
       "8             0.071127            14          2.355124         log2  \n",
       "4             0.071194            12          2.481767         sqrt  \n",
       "9             0.071194            12          3.642341         sqrt  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bayesian search hyperparameter and lags with skopt\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = RandomForestRegressor(random_state=123),\n",
    "                lags      = 10 # Placeholder, the value will be overwritten\n",
    "             )\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [5, 3]\n",
    "\n",
    "# Regressor hyperparameters search space\n",
    "search_space = {'n_estimators'    : Integer(10, 20, \"uniform\", name='n_estimators'),\n",
    "                'min_samples_leaf': Real(1., 3.7, \"log-uniform\", name='min_samples_leaf'),\n",
    "                'max_features'    : Categorical(['log2', 'sqrt'], name='max_features')\n",
    "                }\n",
    "results_1, frozen_trial = bayesian_search_forecaster(\n",
    "                            forecaster            = forecaster,\n",
    "                            y                     = data.loc[:end_val, 'y'],\n",
    "                            lags_grid             = lags_grid,\n",
    "                            search_space          = search_space,\n",
    "                            steps                 = 12,\n",
    "                            metric                = 'mean_squared_error',\n",
    "                            refit                 = True,\n",
    "                            initial_train_size    = len(data.loc[:end_train]),\n",
    "                            fixed_train_size      = True,\n",
    "                            n_trials              = 10,\n",
    "                            random_state          = 123,\n",
    "                            return_best           = False,\n",
    "                            verbose               = False,\n",
    "                            engine                = 'skopt',\n",
    "                            kwargs_create_study   = {},\n",
    "                            kwargs_study_optimize = {}\n",
    "                        )\n",
    "\n",
    "\n",
    "\n",
    "results_2, frozen_trial = bayesian_search_forecaster(\n",
    "                            forecaster            = forecaster,\n",
    "                            y                     = data.loc[:end_val, 'y'],\n",
    "                            lags_grid             = lags_grid,\n",
    "                            search_space          = search_space,\n",
    "                            steps                 = 12,\n",
    "                            metric                =  ['mean_squared_error'],\n",
    "                            refit                 = True,\n",
    "                            initial_train_size    = len(data.loc[:end_train]),\n",
    "                            fixed_train_size      = True,\n",
    "                            n_trials              = 10,\n",
    "                            random_state          = 123,\n",
    "                            return_best           = False,\n",
    "                            verbose               = False,\n",
    "                            engine                = 'skopt',\n",
    "                            kwargs_create_study   = {},\n",
    "                            kwargs_study_optimize = {}\n",
    "                        )\n",
    "\n",
    "\n",
    "results_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef6a7172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_features</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [lags, n_estimators, min_samples_leaf, max_features, metric]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_features</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [lags, n_estimators, min_samples_leaf, max_features, metric]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_1 = results_1.rename(columns={'mean_squared_error': 'metric'})\n",
    "results_2 = results_2.rename(columns={'mean_squared_error': 'metric'})\n",
    "\n",
    "results_1.lags = results_1.lags.astype(str)\n",
    "results_2.lags = results_2.lags.astype(str)\n",
    "\n",
    "cols = ['lags', 'n_estimators', 'min_samples_leaf', 'max_features', 'metric']\n",
    "cols_to_sort = ['lags', 'n_estimators', 'min_samples_leaf', 'max_features']\n",
    "\n",
    "results_1 = results_1[cols].sort_values(by=cols_to_sort).reset_index(drop=True)\n",
    "results_2 = results_2[cols].sort_values(by=cols_to_sort).reset_index(drop=True)\n",
    "\n",
    "equal_hiperparameters = (results_1[cols_to_sort] == results_2[cols_to_sort]).all(axis=1)\n",
    "\n",
    "results_1 = results_1[equal_hiperparameters]\n",
    "results_2 = results_2[equal_hiperparameters]\n",
    "\n",
    "no_match = results_1.metric != results_2.metric\n",
    "display(results_1[no_match])\n",
    "display(results_2[no_match])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec01ee16",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ece7df65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bayesian_search_skopt(\n",
    "    forecaster,\n",
    "    y: pd.Series,\n",
    "    search_space: dict,\n",
    "    steps: int,\n",
    "    metric: Union[str, callable],\n",
    "    initial_train_size: int,\n",
    "    fixed_train_size: bool=True,\n",
    "    exog: Optional[Union[pd.Series, pd.DataFrame]]=None,\n",
    "    lags_grid: Optional[list]=None,\n",
    "    refit: bool=False,\n",
    "    n_trials: int=10,\n",
    "    random_state: int=123,\n",
    "    return_best: bool=True,\n",
    "    verbose: bool=True,\n",
    "    kwargs_gp_minimize: dict={}\n",
    ") -> Tuple[pd.DataFrame, object]:\n",
    "    \"\"\"\n",
    "    Bayesian optimization for a Forecaster object using time series backtesting and skopt library.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    forecaster : ForecasterAutoreg, ForecasterAutoregCustom, ForecasterAutoregDirect, \n",
    "    ForecasterAutoregMultiOutput\n",
    "        Forcaster model.\n",
    "        \n",
    "    y : pandas Series\n",
    "        Training time series values. \n",
    "        \n",
    "    search_space : dict\n",
    "        Dictionary with parameters names (`str`) as keys and Space object from skopt \n",
    "        (Real, Integer, Categorical) as values.\n",
    "\n",
    "    steps : int\n",
    "        Number of steps to predict.\n",
    "        \n",
    "    metric : str, callable\n",
    "        Metric used to quantify the goodness of fit of the model.\n",
    "        \n",
    "        If string:\n",
    "            {'mean_squared_error', 'mean_absolute_error',\n",
    "             'mean_absolute_percentage_error', 'mean_squared_log_error'}\n",
    "\n",
    "        It callable:\n",
    "            Function with arguments y_true, y_pred that returns a float.\n",
    "\n",
    "    initial_train_size : int \n",
    "        Number of samples in the initial train split.\n",
    " \n",
    "    fixed_train_size : bool, default `True`\n",
    "        If True, train size doesn't increases but moves by `steps` in each iteration.\n",
    "\n",
    "    exog : pandas Series, pandas DataFrame, default `None`\n",
    "        Exogenous variable/s included as predictor/s. Must have the same\n",
    "        number of observations as `y` and should be aligned so that y[i] is\n",
    "        regressed on exog[i].\n",
    "           \n",
    "    lags_grid : list of int, lists, np.narray or range, default `None`\n",
    "        Lists of `lags` to try. Only used if forecaster is an instance of \n",
    "        `ForecasterAutoreg`, `ForecasterAutoregDirect` or `ForecasterAutoregMultiOutput`.\n",
    "        \n",
    "    refit : bool, default `False`\n",
    "        Whether to re-fit the forecaster in each iteration of backtesting.\n",
    "        \n",
    "    n_trials : int, default `10`\n",
    "        Number of parameter settings that are sampled in each lag configuration.\n",
    "\n",
    "    random_state : int, default `123`\n",
    "        Sets a seed to the sampling for reproducible output.\n",
    "\n",
    "    return_best : bool, default `True`\n",
    "        Refit the `forecaster` using the best found parameters on the whole data.\n",
    "        \n",
    "    verbose : bool, default `True`\n",
    "        Print number of folds used for cv or backtesting.\n",
    "\n",
    "    kwargs_gp_minimize : dict, default `{}`\n",
    "        Other keyword arguments (key, value mappings) to pass to skopt.gp_minimize().\n",
    "\n",
    "    Returns \n",
    "    -------\n",
    "    results : pandas DataFrame\n",
    "        Results for each combination of parameters.\n",
    "            column lags = predictions.\n",
    "            column params = lower bound of the interval.\n",
    "            column metric = metric value estimated for the combination of parameters.\n",
    "            additional n columns with param = value.\n",
    "\n",
    "    results_opt_best : scipy object\n",
    "        The best optimization result returned as a OptimizeResult object.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(forecaster, ForecasterAutoregCustom):\n",
    "        if lags_grid is not None:\n",
    "            warnings.warn(\n",
    "                '`lags_grid` ignored if forecaster is an instance of `ForecasterAutoregCustom`.'\n",
    "            )\n",
    "        lags_grid = ['custom predictors']\n",
    "        \n",
    "    elif lags_grid is None:\n",
    "        lags_grid = [forecaster.lags]\n",
    "   \n",
    "    lags_list = []\n",
    "    params_list = []\n",
    "    metric_list = []\n",
    "    results_opt_best = None\n",
    "\n",
    "    for key in search_space.keys():\n",
    "        if key != search_space[key].name:\n",
    "            raise Exception(\n",
    "                f\"\"\"Some of the key values do not match the Space object name from skopt.\n",
    "                    {key} != {search_space[key].name}.\"\"\"\n",
    "            )\n",
    "\n",
    "    search_space = list(search_space.values())\n",
    "\n",
    "    # Objective function using backtesting_forecaster\n",
    "    @use_named_args(search_space)\n",
    "    def _objective(\n",
    "        forecaster         = forecaster,\n",
    "        y                  = y,\n",
    "        exog               = exog,\n",
    "        initial_train_size = initial_train_size,\n",
    "        fixed_train_size   = fixed_train_size,\n",
    "        steps              = steps,\n",
    "        metric             = metric,\n",
    "        refit              = refit,\n",
    "        verbose            = verbose,\n",
    "        **params\n",
    "    ) -> float:\n",
    "        \n",
    "        forecaster.set_params(**params)\n",
    "        \n",
    "        metric, _ = backtesting_forecaster(\n",
    "                        forecaster         = forecaster,\n",
    "                        y                  = y,\n",
    "                        exog               = exog,\n",
    "                        steps              = steps,\n",
    "                        metric             = metric,\n",
    "                        initial_train_size = initial_train_size,\n",
    "                        fixed_train_size   = fixed_train_size,\n",
    "                        refit              = refit,\n",
    "                        verbose            = verbose\n",
    "                    )\n",
    "\n",
    "        return abs(metric)\n",
    "\n",
    "    print(\n",
    "        f\"\"\"Number of models compared: {n_trials*len(lags_grid)}, {n_trials} bayesian search in each lag configuration.\"\"\"\n",
    "    )\n",
    "\n",
    "    for lags in tqdm(lags_grid, desc='loop lags_grid', position=0, ncols=90):\n",
    "        \n",
    "        if isinstance(forecaster, (ForecasterAutoreg, ForecasterAutoregDirect, \n",
    "        ForecasterAutoregMultiOutput)):\n",
    "            forecaster.set_lags(lags)\n",
    "            lags = forecaster.lags.copy()\n",
    "        \n",
    "        results_opt = gp_minimize(\n",
    "                        func         = _objective,\n",
    "                        dimensions   = search_space,\n",
    "                        n_calls      = n_trials,\n",
    "                        random_state = random_state,\n",
    "                        **kwargs_gp_minimize\n",
    "                      )\n",
    "\n",
    "        for i in range(len(results_opt.x_iters)):\n",
    "            params = {param.name: results_opt.x_iters[i][j] \n",
    "                      for j, param in enumerate(search_space)}\n",
    " \n",
    "            params_list.append(params)\n",
    "            lags_list.append(lags)\n",
    "            metric_list.append(results_opt.func_vals[i])\n",
    "\n",
    "        if results_opt_best is None:\n",
    "            results_opt_best = results_opt\n",
    "        else:\n",
    "            if results_opt.fun < results_opt_best.fun:\n",
    "                results_opt_best = results_opt\n",
    "        \n",
    "    results = pd.DataFrame({\n",
    "                'lags'  : lags_list,\n",
    "                'params': params_list,\n",
    "                'metric': metric_list\n",
    "              })\n",
    "    \n",
    "    results = results.sort_values(by='metric', ascending=True)\n",
    "    results = pd.concat([results, results['params'].apply(pd.Series)], axis=1)\n",
    "    \n",
    "    if return_best:\n",
    "        \n",
    "        best_lags = results['lags'].iloc[0]\n",
    "        best_params = results['params'].iloc[0]\n",
    "        best_metric = results['metric'].iloc[0]\n",
    "        \n",
    "        if isinstance(forecaster, (ForecasterAutoreg, ForecasterAutoregDirect, \n",
    "        ForecasterAutoregMultiOutput)):\n",
    "            forecaster.set_lags(best_lags)\n",
    "        forecaster.set_params(**best_params)\n",
    "        forecaster.fit(y=y, exog=exog)\n",
    "        \n",
    "        print(\n",
    "            f\"`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \\n\"\n",
    "            f\"  Lags: {best_lags} \\n\"\n",
    "            f\"  Parameters: {best_params}\\n\"\n",
    "            f\"  Backtesting metric: {best_metric}\\n\"\n",
    "        )\n",
    "\n",
    "    return results, results_opt_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61df2707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 20,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 2/2 [00:05<00:00,  2.93s/it]\n"
     ]
    }
   ],
   "source": [
    "# Bayesian search hyperparameter and lags with skopt\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = RandomForestRegressor(random_state=123),\n",
    "                lags      = 10 # Placeholder, the value will be overwritten\n",
    "             )\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [5, 3]\n",
    "\n",
    "# Regressor hyperparameters search space\n",
    "search_space = {'n_estimators'    : Integer(10, 20, \"uniform\", name='n_estimators'),\n",
    "                'min_samples_leaf': Real(1., 3.7, \"log-uniform\", name='min_samples_leaf'),\n",
    "                'max_features'    : Categorical(['log2', 'sqrt'], name='max_features')\n",
    "                }\n",
    "results_1, frozen_trial = bayesian_search_forecaster(\n",
    "                            forecaster            = forecaster,\n",
    "                            y                     = data.loc[:end_val, 'y'],\n",
    "                            lags_grid             = lags_grid,\n",
    "                            search_space          = search_space,\n",
    "                            steps                 = 12,\n",
    "                            metric                = 'mean_squared_error',\n",
    "                            refit                 = True,\n",
    "                            initial_train_size    = len(data.loc[:end_train]),\n",
    "                            fixed_train_size      = True,\n",
    "                            n_trials              = 10,\n",
    "                            random_state          = 123,\n",
    "                            return_best           = False,\n",
    "                            verbose               = False,\n",
    "                            engine                = 'skopt',\n",
    "                            kwargs_create_study   = {},\n",
    "                            kwargs_study_optimize = {}\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76f9bc2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 12, 'min_samples_leaf': 3.642...</td>\n",
       "      <td>0.068957</td>\n",
       "      <td>12</td>\n",
       "      <td>3.642341</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 12, 'min_samples_leaf': 2.481...</td>\n",
       "      <td>0.068957</td>\n",
       "      <td>12</td>\n",
       "      <td>2.481767</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 2.272...</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>14</td>\n",
       "      <td>2.272179</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 2.134...</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>14</td>\n",
       "      <td>2.134928</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 2.355...</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>14</td>\n",
       "      <td>2.355124</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.750...</td>\n",
       "      <td>0.069218</td>\n",
       "      <td>17</td>\n",
       "      <td>1.750301</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.901...</td>\n",
       "      <td>0.069218</td>\n",
       "      <td>17</td>\n",
       "      <td>1.901317</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.751...</td>\n",
       "      <td>0.069218</td>\n",
       "      <td>17</td>\n",
       "      <td>1.751693</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 15, 'min_samples_leaf': 2.634...</td>\n",
       "      <td>0.069430</td>\n",
       "      <td>15</td>\n",
       "      <td>2.634133</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 16, 'min_samples_leaf': 1.778...</td>\n",
       "      <td>0.069501</td>\n",
       "      <td>16</td>\n",
       "      <td>1.778914</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.751...</td>\n",
       "      <td>0.070486</td>\n",
       "      <td>17</td>\n",
       "      <td>1.751693</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.750...</td>\n",
       "      <td>0.070486</td>\n",
       "      <td>17</td>\n",
       "      <td>1.750301</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.901...</td>\n",
       "      <td>0.070486</td>\n",
       "      <td>17</td>\n",
       "      <td>1.901317</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 16, 'min_samples_leaf': 1.778...</td>\n",
       "      <td>0.070671</td>\n",
       "      <td>16</td>\n",
       "      <td>1.778914</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 15, 'min_samples_leaf': 2.634...</td>\n",
       "      <td>0.070912</td>\n",
       "      <td>15</td>\n",
       "      <td>2.634133</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 2.272...</td>\n",
       "      <td>0.071127</td>\n",
       "      <td>14</td>\n",
       "      <td>2.272179</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 2.134...</td>\n",
       "      <td>0.071127</td>\n",
       "      <td>14</td>\n",
       "      <td>2.134928</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 2.355...</td>\n",
       "      <td>0.071127</td>\n",
       "      <td>14</td>\n",
       "      <td>2.355124</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 12, 'min_samples_leaf': 2.481...</td>\n",
       "      <td>0.071194</td>\n",
       "      <td>12</td>\n",
       "      <td>2.481767</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 12, 'min_samples_leaf': 3.642...</td>\n",
       "      <td>0.071194</td>\n",
       "      <td>12</td>\n",
       "      <td>3.642341</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               lags                                             params  \\\n",
       "19        [1, 2, 3]  {'n_estimators': 12, 'min_samples_leaf': 3.642...   \n",
       "14        [1, 2, 3]  {'n_estimators': 12, 'min_samples_leaf': 2.481...   \n",
       "13        [1, 2, 3]  {'n_estimators': 14, 'min_samples_leaf': 2.272...   \n",
       "12        [1, 2, 3]  {'n_estimators': 14, 'min_samples_leaf': 2.134...   \n",
       "18        [1, 2, 3]  {'n_estimators': 14, 'min_samples_leaf': 2.355...   \n",
       "16        [1, 2, 3]  {'n_estimators': 17, 'min_samples_leaf': 1.750...   \n",
       "11        [1, 2, 3]  {'n_estimators': 17, 'min_samples_leaf': 1.901...   \n",
       "10        [1, 2, 3]  {'n_estimators': 17, 'min_samples_leaf': 1.751...   \n",
       "17        [1, 2, 3]  {'n_estimators': 15, 'min_samples_leaf': 2.634...   \n",
       "15        [1, 2, 3]  {'n_estimators': 16, 'min_samples_leaf': 1.778...   \n",
       "0   [1, 2, 3, 4, 5]  {'n_estimators': 17, 'min_samples_leaf': 1.751...   \n",
       "6   [1, 2, 3, 4, 5]  {'n_estimators': 17, 'min_samples_leaf': 1.750...   \n",
       "1   [1, 2, 3, 4, 5]  {'n_estimators': 17, 'min_samples_leaf': 1.901...   \n",
       "5   [1, 2, 3, 4, 5]  {'n_estimators': 16, 'min_samples_leaf': 1.778...   \n",
       "7   [1, 2, 3, 4, 5]  {'n_estimators': 15, 'min_samples_leaf': 2.634...   \n",
       "3   [1, 2, 3, 4, 5]  {'n_estimators': 14, 'min_samples_leaf': 2.272...   \n",
       "2   [1, 2, 3, 4, 5]  {'n_estimators': 14, 'min_samples_leaf': 2.134...   \n",
       "8   [1, 2, 3, 4, 5]  {'n_estimators': 14, 'min_samples_leaf': 2.355...   \n",
       "4   [1, 2, 3, 4, 5]  {'n_estimators': 12, 'min_samples_leaf': 2.481...   \n",
       "9   [1, 2, 3, 4, 5]  {'n_estimators': 12, 'min_samples_leaf': 3.642...   \n",
       "\n",
       "    mean_squared_error  n_estimators  min_samples_leaf max_features  \n",
       "19            0.068957            12          3.642341         sqrt  \n",
       "14            0.068957            12          2.481767         sqrt  \n",
       "13            0.069073            14          2.272179         log2  \n",
       "12            0.069073            14          2.134928         log2  \n",
       "18            0.069073            14          2.355124         log2  \n",
       "16            0.069218            17          1.750301         log2  \n",
       "11            0.069218            17          1.901317         sqrt  \n",
       "10            0.069218            17          1.751693         sqrt  \n",
       "17            0.069430            15          2.634133         log2  \n",
       "15            0.069501            16          1.778914         log2  \n",
       "0             0.070486            17          1.751693         sqrt  \n",
       "6             0.070486            17          1.750301         log2  \n",
       "1             0.070486            17          1.901317         sqrt  \n",
       "5             0.070671            16          1.778914         log2  \n",
       "7             0.070912            15          2.634133         log2  \n",
       "3             0.071127            14          2.272179         log2  \n",
       "2             0.071127            14          2.134928         log2  \n",
       "8             0.071127            14          2.355124         log2  \n",
       "4             0.071194            12          2.481767         sqrt  \n",
       "9             0.071194            12          3.642341         sqrt  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('skforecast': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "369.6px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "b01223d1c8e1f1b59110ab07e8a75a8d7363860deee4f879ff05c69d9593389e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
