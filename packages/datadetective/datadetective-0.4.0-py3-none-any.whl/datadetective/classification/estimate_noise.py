# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/15-estimate-noise.ipynb.

# %% auto 0
__all__ = []

# %% ../../nbs/15-estimate-noise.ipynb 2
import numpy as np
import pandas as pd
from loguru import logger

# %% ../../nbs/15-estimate-noise.ipynb 4
from scipy.sparse import coo_matrix

from datadetective.util import set_logger

# %% ../../nbs/15-estimate-noise.ipynb 17
def avg_confidence(
    *,
    probas: np.ndarray,
    labels: np.ndarray,
):
    """Compute the average model confidence for samples in each class. If there is no sample in some specific class, take np.nan."""
    m_class = probas.shape[1]  # number of classes
    thress = np.zeros(m_class)
    for j in range(m_class):
        logger.debug(f"j {j}")
        i = labels == j
        logger.debug(f"i {i}")
        if i.any():
            p_ij = probas[i, j]
            logger.debug(f"p_ij {p_ij}")
            thress[j] = p_ij.mean()
        else:
            thress[j] = np.nan
    logger.info(thress)
    return thress

# %% ../../nbs/15-estimate-noise.ipynb 23
def find_likeliests(
    *,
    thress: np.ndarray,  # thresholds for each class
    probas: np.ndarray,  # computed probabily matrix
):
    """
    Dự đoán nhãn đáng tin nhất cho từng mẫu dữ liệu.
    Trường hợp không dự đoán được thì gán -1 vào hàng tương ứng.
    """
    likelies = probas > thress
    ps_filtered = np.where(likelies, probas - thress, -1)
    most_ll = ps_filtered.argmax(axis=1)
    most_ll = np.where((likelies).any(axis=1), most_ll, -1)
    logger.debug(most_ll)
    return most_ll

# %% ../../nbs/15-estimate-noise.ipynb 32
def est_noise_mat(
    *,
    likeliests: np.ndarray,  # likeliest labels
    labels: np.ndarray,  # observed labels
    m_class: int = 0,  # number of classes
    normalize: bool = False,
    cleanlab_compat: bool = False,  # CleanLab compatible. See https://github.com/cleanlab/cleanlab/blob/3fb4133a5c4f132ecdcce779580dc3aadbe52144/cleanlab/count.py#L295-L296
) -> coo_matrix:
    z = np.column_stack((labels[likeliests >= 0], likeliests[likeliests >= 0]))
    ij, cnt = np.unique(z, axis=0, return_counts=True)
    if not m_class:
        m_class = max([max(labels), max(likeliests)]) + 1
        logger.debug("m_class {}", m_class)
    counts_mat = coo_matrix((cnt, (ij[:, 0], ij[:, 1])), shape=(m_class, m_class))
    logger.debug("counts_mat\n{}", counts_mat.toarray())
    if cleanlab_compat:
        counts_mat.setdiag(counts_mat.diagonal().clip(min=1))  # to avoid division by 0
    # number of observed (given) samples in each class
    o_cnt = np.array(
        [
            {k: v for k, v in zip(*np.unique(labels, return_counts=True))}.get(i, 0)
            for i in range(m_class)
        ]
    )
    logger.debug("o_cnt\n{}", o_cnt)
    # number of observed (given) samples in each likely class
    l_cnt = np.array(
        [
            {k: v for k, v in zip(*np.unique(likeliests, return_counts=True))}.get(i, 0)
            for i in range(m_class)
        ]
    )
    l_cnt = np.maximum(l_cnt, 1)  # to avoid division by 0
    logger.debug("l_cnt\n{}", l_cnt)
    o_l_rate = o_cnt / l_cnt
    logger.info("o_l_rate\n{}", o_l_rate)
    res = counts_mat.multiply(o_l_rate)
    res = res / res.sum()
    logger.debug("res\n{}", res.toarray())
    if not normalize:
        res = res * len(labels)
    return res

# %% ../../nbs/15-estimate-noise.ipynb 34
def est_noise_mask(
    *,
    likeliests: np.ndarray,  # likeliest labels
    labels: np.ndarray,  # observed labels
):
    """Estimate number of erronous labels"""
    noise_mask = (likeliests != labels) & (likeliests > -1)
    logger.debug(noise_mask)
    return noise_mask

# %% ../../nbs/15-estimate-noise.ipynb 35
def est_noise_cnt(
    *,
    likeliests: np.ndarray,  # likeliest labels
    labels: np.ndarray,  # observed labels
    m_class: int = 0,  # number of classes
    normalize: bool = False,  # set True to output a percentage instead of a number
) -> int:
    """Estimate number of erronous labels"""
    # noise_mask = est_noise_mask(likeliests=likeliests, labels=labels)
    # noise_cnt = sum(noise_mask)
    # if normalize:
    #     noise_cnt /= len(labels)

    noise_mat = est_noise_mat(
        labels=labels, likeliests=likeliests, m_class=m_class, normalize=normalize
    )
    noise_cnt = (1 if normalize else len(labels)) - sum(noise_mat.diagonal())

    logger.debug("noise_cnt {}", noise_cnt)
    assert noise_cnt >= 0
    if not normalize:
        noise_cnt = int(noise_cnt)
    return noise_cnt
