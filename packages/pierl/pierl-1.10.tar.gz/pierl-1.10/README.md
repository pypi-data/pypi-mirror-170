# PyRL
Environment Agnostic RL algorithm implementations using Pytorch.

Code is type-hinted & uses minibatches - a common downfall to public libraries

See exmples.ipynb for, well, some examples. Algos implemented:

1. *Deep Q Learning (DQN)* <sub><sup> ([Mnih et al. 2013](https://arxiv.org/pdf/1312.5602.pdf)) </sup></sub>  
2. *DQN Experience Replay*  <sub><sup> ([Mnih et al. 2013](https://arxiv.org/pdf/1312.5602.pdf)) </sup></sub> 
3. *DQN with Fixed targets* <sub><sup>([Mnih et al. 2013](https://arxiv.org/pdf/1312.5602.pdf)) </sup></sub> 
4. *Double Q Learning (DDQN)* <sub><sup> ([arXiv:1509.06461v3 [cs.LG] 8 Dec 2015](https://arxiv.org/pdf/1509.06461v3.pdf)) </sup></sub>   
5. REINFORCE <sub><sup> ([Richard S. Sutton et al 1999](https://proceedings.neurips.cc/paper/1999/file/464d828b85b0bed98e80ade0a5c43b0f-Paper.pdf))
6. Advantage Actor Critic ([arXiv:1611.06256](https://arxiv.org/abs/1611.06256))

 --- UPCOMING ---
3. PPO